{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確次數:9361 , 錯誤次數:639\n",
      "準確率:93.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class neuralNetwork:\n",
    "    #初始化神經網路\n",
    "    def __init__(self, inputnodes, hidden1nodes, hidden2nodes, outputnodes, learning_rate):\n",
    "        self.inodes=inputnodes#輸入層節點個數\n",
    "        self.h1nodes=hidden1nodes#第一層隱藏層節點個數\n",
    "        self.h2nodes=hidden2nodes#第一層隱藏層節點個數\n",
    "        self.onodes=outputnodes#輸出層節點個數\n",
    "        self.lr=learning_rate#學習率\n",
    "        #輸入層到第一層隱藏層的權重\n",
    "        #self.wih1=np.random.normal(0.0, pow(self.h1nodes,-0.5), (self.h1nodes, self.inodes))\n",
    "        #第一層隱藏層到第二層隱藏層的權重\n",
    "        #self.wh1h2=np.random.normal(0.0, pow(self.h2nodes,-0.5), (self.h2nodes, self.h1nodes))\n",
    "        #第二層隱藏層到輸出層的權重\n",
    "        #self.wh2o=np.random.normal(0.0, pow(self.onodes,-0.5), (self.onodes, self.h2nodes))\n",
    "        #另一種方法\n",
    "        self.wih1=np.random.rand(self.h1nodes, self.inodes)-0.5\n",
    "        self.wh1h2=np.random.rand(self.h2nodes, self.h1nodes)-0.5\n",
    "        self.wh2o=np.random.rand(self.onodes, self.h2nodes)-0.5\n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):#訓練神經網路模型\n",
    "        inputs=np.array(inputs_list, ndmin=2).T#這是行向量\n",
    "        targets=np.array(targets_list, ndmin=2).T#這是行向量\n",
    "        \n",
    "        hidden1_inputs=np.dot(self.wih1, inputs)#第一層隱藏層的輸入，這是行向量\n",
    "        hidden1_outputs=(1/(1+np.exp(-1*hidden1_inputs)))#第一層隱藏層的輸出，這是行向量\n",
    "        \n",
    "        hidden2_inputs=np.dot(self.wh1h2, hidden1_outputs)#第二層隱藏層的輸入，這是行向量\n",
    "        hidden2_outputs=(1/(1+np.exp(-1*hidden2_inputs)))#第二層隱藏層的輸出，這是行向量\n",
    "        \n",
    "        final_inputs=np.dot(self.wh2o, hidden2_outputs)#輸出層的輸入，這是行向量\n",
    "        final_outputs=(1/(1+np.exp(-1*final_inputs)))#輸出層的輸出，這是行向量\n",
    "        \n",
    "        \n",
    "        output_errors=(targets-final_outputs)*final_outputs*(1-final_outputs)#輸出層輸出誤差，這是行向量\n",
    "        hidden2_errors=(np.dot(self.wh2o.T, output_errors))*(hidden2_outputs*(1-hidden2_outputs))#第二層隱藏層輸出的誤差，這是行向量\n",
    "        hidden1_errors=(np.dot(self.wh1h2.T, hidden2_errors))*(hidden1_outputs*(1-hidden1_outputs))#第一層隱藏層輸出的誤差，這是行向量\n",
    "        \n",
    "        #更新第二隱藏層至輸出層的權重\n",
    "        #output_errors*final_outputs*(1.0-final_outputs)為行向量對應元素相乘\n",
    "        #hidden_outputs.T，轉成列向量，dot完才會變成與權重相當大小的矩陣\n",
    "        self.wh2o=self.wh2o+self.lr*np.dot(output_errors,hidden2_outputs.T)\n",
    "        #更新第一隱藏層至第二隱藏層的權重\n",
    "        self.wh1h2=self.wh1h2+self.lr*np.dot(hidden2_errors,hidden1_outputs.T)\n",
    "        #更新輸出層至隱藏層的權重\n",
    "        self.wih1=self.wih1+self.lr*np.dot(hidden1_errors,inputs.T)\n",
    "        pass\n",
    "    \n",
    "    def query(self, inputs_list):#丟輸入進來，回傳輸出值\n",
    "        inputs=np.array(inputs_list, ndmin=2).T#這是行向量\n",
    "        \n",
    "        hidden1_inputs=np.dot(self.wih1, inputs)#第一層隱藏層的輸入，這是行向量\n",
    "        hidden1_outputs=(1/(1+np.exp(-1*hidden1_inputs)))#第一層隱藏層的輸出，這是行向量\n",
    "        \n",
    "        hidden2_inputs=np.dot(self.wh1h2, hidden1_outputs)#第二層隱藏層的輸入，這是行向量\n",
    "        hidden2_outputs=(1/(1+np.exp(-1*hidden2_inputs)))#第二層隱藏層的輸出，這是行向量\n",
    "        \n",
    "        final_inputs=np.dot(self.wh2o, hidden2_outputs)#輸出層的輸入，這是行向量\n",
    "        final_outputs=(1/(1+np.exp(-1*final_inputs)))#輸出層的輸出，這是行向量\n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "\n",
    "inputnodes=784#因為圖片像素為28*28=784\n",
    "hidden1nodes=100#沒有最佳選擇方法，但不須高於inputnodes，在簡短形式下網路應該有能力發現特徵\n",
    "hidden2nodes=100\n",
    "outputnodes=10#數字=0~9\n",
    "learning_rate=0.5\n",
    "#實體化一個神經網路\n",
    "n=neuralNetwork(inputnodes, hidden1nodes, hidden2nodes, outputnodes, learning_rate)\n",
    "#載入訓練集\n",
    "training_data_file=open(\"mnist_train.csv\",'r')\n",
    "training_data_list=training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "#開始訓練神經網路\n",
    "epoch=1\n",
    "for e in range(epoch):\n",
    "    for record in training_data_list:\n",
    "        all_value=record.split(',')#一次取一條數據\n",
    "        inputs=(np.asfarray(all_value[1:])/255*0.99)+0.01#輸入要scale成0.01~1\n",
    "        targets=np.zeros(outputnodes)+0.01\n",
    "        targets[int(all_value[0])]=0.99#目標值要符合sigmoid的值域\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n",
    "#=================測試區=============================\n",
    "\n",
    "acc=0\n",
    "err=0\n",
    "test_data_file=open(\"mnist_test.csv\",'r')\n",
    "test_data_list=test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "for record in test_data_list:\n",
    "    all_value=record.split(',')\n",
    "    correct_label=int(all_value[0])\n",
    "    inputs=(np.asfarray(all_value[1:])/255*0.99)+0.01\n",
    "    outputs=n.query(inputs)\n",
    "    predict_label=np.argmax(outputs)#回傳最大值所在的索引\n",
    "    #print(\"correct_label:%s , predict_label:%s\" %(correct_label,predict_label))\n",
    "    if(correct_label==predict_label):\n",
    "        acc=acc+1\n",
    "    elif(correct_label!=predict_label):\n",
    "        err=err+1\n",
    "    pass\n",
    "print(\"正確次數:%s , 錯誤次數:%s\" %(acc,err))\n",
    "accuracy=acc/(acc+err)*100\n",
    "print(\"準確率:%s\" %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
